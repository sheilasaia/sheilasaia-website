---
title: "APIs to the Rescue (& the Census of Agriculture)"
author: "Sheila Saia"
date: '2019-01-04'
categories: ["R"]
tags: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE, warning = FALSE, eval = TRUE)
```

# Background

This post was originally posted on Jan. 4, 2019 but was revised on May 14, 2020.

Application program interfaces (APIs) help users access ("API request") and retrieve ("API response") data from web-based, data servers via programs like R, Python, etc. If you're interested in more details, several others before me have done a great job writing about API's and R: [this post by C. Waldhauser](https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/) and [this post by T. Clavelle](https://tclavelle.github.io/blog/r_and_apis/).

I recently learned about a few R packages that help users interface directly with APIs and a few of these are especially interesting for water-minded, data loving people like me. For example the [`tidycensus` package](https://walkerke.github.io/tidycensus/) developed by [Kyle Walker](http://personal.tcu.edu/kylewalker/) allows R users to access the US Census API and download data directly into their R environment. It's awesome. Additionally, [I previously wrote about](https://sheilasaia.rbind.io/post/2018-08-04-usgs-rollify/) the US Geologic Survey and US Environmental Protection Agency's [`dataRetrieval` package](https://cran.r-project.org/web/packages/dataRetrieval/dataRetrieval.pdf) that interfaces with the National Water Information System API. Some APIs will require you to have an API key (e.g., the US Census) while others don't (e.g., the National Water Information System). The key is meant to ensure security on your end as well as on the end of the API administrator. In the case of the US Census, they can keep track of your queries and also make sure that you have permission to access certain types of data, etc. You can easily request an US Census API key [here](https://api.census.gov/data/key_signup.html) and read more about the US Census API [here](https://www.census.gov/data/developers/guidance/api-user-guide.html).

But what if you're working with an API that doesn't already have an R package associated with it? This is the case for the data associated with the US Department of Agriculture National Agricultural Statistics Service (NASS). I could click through the options on NASS's Quick Stats page [on the web](https://quickstats.nass.usda.gov/) and download the data that way; however, I wanted to use R to access the Quick Stats API directly.

Before jumping into the code, just a brief explainer on the NASS API. The NASS API includes two different types of data:

1. NASS Agriculture Resource Management Survey (ARMS) - This survey includes data on the "production practices, resource use, and economic well-being of America's farms and ranches" [(NASS ARMS Webiste)](https://www.nass.usda.gov/Surveys/Guide_to_NASS_Surveys/Ag_Resource_Management/).


2. NASS Census of Agriculture - This survey is conducted every 5 years and includes data on the number of US farms and ranches and the people who operate them (as long as more than $1000 was raised from associated agricultural goods). It also includes data on land use, land ownership, production practices, income, and expenses [(NASS Census of Agriculture Website)](https://www.nass.usda.gov/AgCensus/index.php).

# Goals of This Post

The main goal of this blog post is to:

- Download and plot Agriculture Census data from NASS Quick Stats API using R.

Special thanks to [Natalie Nelson](http://nelson.rbind.io/) of NC State University and Andrew Dau of NASS for some of the R code that I modified for this post.

# Set Up

First let's load the R libraries that we'll need to run the code in this post.

```{r load libraries}
library(httr)
library(jsonlite)
library(tidycensus)
library(tidyverse)
library(purrr)
library(mapview)
```

The `httr` and `jsonlite` packages are necessary for interfacing with the Quick Stats API and reformatting API outputs so they can be used in R.

Let's use the `tidycensus` package to get some county boundaries. This will provide some spatial context for our analysis.

The `tidyverse` and `mapview` packages will help us wrangle and visualize the API outputs.

The `purrr` package will help us repetitively apply the same function to each row of the API outputs.

## Census API Set Up

As I mentioned above, many APIs require that you have a personal API key to access the data stored within them. To run the code in this post you'll need to make sure you request a Census API key (see instructions above) and a NASS API key (see instructions below). Once you have your API keys, keep them all in one safe spot. I recommend a text file somewhere rememberable on your (password protected) computer.

If you've never installed your Census API key in your R session, you'll want to install your API key for later use.

```{r first time census key, eval=FALSE}
CENSUS_API_KEY <- "YOUR API KEY GOES HERE"
census_api_key(CENSUS_API_KEY, install = TRUE)

# The second line of code above will make an entry in your .Renviron file called "CENSUS_API_KEY".
```

If you've already installed your Census API key, you should be good to go, but you can always check to make sure it's in your R environment using the code below.

```{r not first time census key, eval=FALSE}
Sys.getenv("CENSUS_API_KEY")
```

If you want to get tabular *and* spatial census data using the `tidycensus` package, you will need to run the code below each time you start a new R session. Spatial census data includes, for example, census tract boundaries.

```{r setting tigris options}
options(tigris_use_cache = TRUE)
```

## NASS API Set Up

Be sure to also apply for a NASS API key. We'll use this later but will define it here as a string called `NASS_API_KEY`. You can apply for a NASS API key [here](https://quickstats.nass.usda.gov/api)

```{r define NASS api, eval=FALSE}
NASS_API_KEY <- "ADD YOUR NASS API KEY HERE"
```

If you want to save your NASS API key to your R environment, you can use the code below. Setting the NASS API key in your R environment will keep it hidden and accessible only to you. This might be important if you're planning to pass along your script to someone else...or post it on your blog. ;) Note, you would have to do this each time you open R.

```{r define NASS api from env, eval=FALSE}
Sys.setenv(NASS_API_KEY = NASS_API_KEY)

# To check that it is there, use this code:
Sys.getenv("NASS_API_KEY")
```

To use your NASS API in code later on call it and assign it to a variable.

```{r use NASS key from env}
NASS_API_KEY <- Sys.getenv("NASS_API_KEY")
```

If you want to be very organized and secure you can add your NASS API key to your .Renviron file. You will only need to do this once and then R will automatically load the key into your working environment whenever you start a new R session. If you're interested in doing this and not too afraid of the command line, checkout [this stackoverflow post](https://stackoverflow.com/questions/40788645/how-to-create-renviron-file). Note, that if you have already run `census_api_key()` you will not need to make a new .Renviron file. It will already exist in your HOME directory.

# API Data Query

Now, we'll define the NASS url and path. In the path you'll have to specify what type of data you want to query. To specify these you can go to [https://quickstats.nass.usda.gov/](https://quickstats.nass.usda.gov/) to see all your commodity options. I haven't figured out another way to do this but please [contact me](mailto:ssaia@ncsu.edu) if you find an alternative.

For this post I'm selecting the "AG_LAND" commodity, which includes information on the acreage of irrigated farm and ranch lands, because this is the wateR blog after all. Other commodities might include specific crops, etc. I'm also selecting the state of North Carolina (NC) because it seems to always be the subject of spatial mapping [(e.g., see this post)](https://r-spatial.github.io/sf/reference/geos_combine.html) in R and is also where I live. ;) You can also leave off the last "&state_alpha=NC" part of the string to get data from all states.

```{r define strings}
# NASS url
nass_url <- "http://quickstats.nass.usda.gov"

# commodity description of interest
my_commodity_desc <- "AG LAND"

# short description of interest (i.e., 'data item' on NASS Quick Stats website)
my_short_desc1 <- "AG LAND, IRRIGATED - ACRES"
my_short_desc2 <- "AG LAND - ACRES"

# query start year
my_year <- "2006"

# state of interest
my_state <- "NC"

# final path string
path_nc_irrig_land <- paste0("api/api_GET/?key=", NASS_API_KEY, "&commodity_desc=", my_commodity_desc, "&short_desc=", my_short_desc1, "&short_desc=", my_short_desc2, "&year__GE=", my_year, "&state_alpha=", my_state)
```

Let's query the NASS API.

```{r query api}
raw_result_nc_irrig_land <- GET(url = nass_url, path = path_nc_irrig_land)
```

We can check to see if it worked by looking at `status_code`. To read more about the different status codes and their meaning you can visit [https://en.wikipedia.org/wiki/List_of_HTTP_status_codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes).

```{r check status}
raw_result_nc_irrig_land$status_code
```

Great! We're wanting to see status code 200 here. It means our query was received and responded to.

# Reformatting API Query Output

If we look at this in your R session it will come in as a 'Large response' or in other words as a JSON object. For simplicity sake, we can think of this as a list of lists (i.e., nested lists). We'll ultimately convert this to a data frame because it's a little easier to view in R.

We'll start unpacking the JSON object using `rawToChar()`. We can check the size and look at the first few characters.

```{r to raw character string}
char_raw_nc_irrig_land <- rawToChar(raw_result_nc_irrig_land$content)

# check size of object
nchar(char_raw_nc_irrig_land)

# view first 50 characthers
substr(char_raw_nc_irrig_land, 1, 50)
```
 
This is still a little hard to work with so let's use `fromJSON()` and convert the raw character strings to a large list. Next, we'll use `pmap_dfr` from the `purrr` package to loop over each list and bind it by row to make a data frame.
 
```{r to df}
list_raw_nc_irrig_land <- fromJSON(char_raw_nc_irrig_land)

# view first element (it's big so we'll comment it here)
# list_raw_ag_land[[1]]

# apply rbind to each row of the list and convert to a data frame
nc_irrig_land_raw_data <- pmap_dfr(list_raw_nc_irrig_land, rbind)

# look at the data frame
head(nc_irrig_land_raw_data)
```

This looks ok but there are still some things that would be nice to clean up. As mentioned above, we want to focus on the acres of irrigated lands in NC. For simplicity, we'll just look at farms/ranches with 2,000 ac or more under operation. Let's step through each line in the piped (i.e., `%>%`) code below. See the in-line comments for the details.

```{r wrangle data}
nc_irrigated <- nc_irrig_land_raw_data %>%
  
  # filter to select county level irrigation data where farms/ranches with 2,000+ ac operation and irrigation status to get total acres of ag land in county
  filter(agg_level_desc == "COUNTY") %>%
  filter(unit_desc == "ACRES") %>%
  filter(domaincat_desc == "AREA OPERATED: (2,000 OR MORE ACRES)" | domaincat_desc == "IRRIGATION STATUS: (ANY ON OPERATION)") %>%

  # trim white space from ends (note: 'Value' is a character here, not a number)
  mutate(value_trim = str_trim(Value)) %>%
  
  # select only the columns we'll need
  select(state_name, state_alpha, state_ansi, county_code, county_name, asd_desc,
         agg_level_desc, year, prodn_practice_desc_char = prodn_practice_desc, domaincat_desc, 
         short_desc, value_ac_per_yr_char=value_trim, unit_desc) %>%
  
  # filter out entries with codes '(D)' and '(Z)'
  filter(value_ac_per_yr_char != "(D)" & value_ac_per_yr_char != "(Z)") %>% 
  
  # remove commas from number values and convert to R numeric class
  mutate(value_ac_per_yr = as.numeric(str_remove(value_ac_per_yr_char, ","))) %>%
  
  # change blanks to underscores in prodn_practice_desc_char for latter processing
  mutate(prodn_practice_desc = str_replace_all(str_to_lower(prodn_practice_desc_char),
                                               "[ ]", "_")) %>%
  
  # remove unnecessary columns
  select(-value_ac_per_yr_char, -prodn_practice_desc_char) %>%
  #arrange(county_code, year) 
  
  # we have 2007, 2012, and 2017 data and we want irrigated land acreage and total land acreage
  # (to calculate a percentage of irrigated land) so we use n()>1 to filter out counties
  # that have both types of acreage for each year
  group_by(county_code, year) %>%
  filter(n()>1) %>%
  
  # drop columns we don't need
  select(-domaincat_desc, -short_desc) %>%
  
  # pivot wide irrigated and total lands operated data and calculate percent irrigated
  pivot_wider(names_from = prodn_practice_desc, values_from = value_ac_per_yr) %>%
  mutate(percent_irrigated = round(irrigated/all_production_practices*100, 1)) %>%
  
  # make a column with the county name and year (we'll need this for plotting)
  mutate(county_year = paste0(str_to_lower(county_name), "_", year)) %>%
  
  # make GEOID column to match up with county level spatial data (we'll need this for mapping)
  mutate(GEOID = paste0(state_ansi, county_code)) %>%
  ungroup()
```

Let's look at the first few rows of the final reformatted NASS data showing the amount of irrigated acres in NC for 2007, 2012, and 2017.

```{r check data}
head(nc_irrigated)
```

# Plotting NASS Data

Now that we have this nicely formatted data, we can make some figures! Let's start by making some bar charts comparing the percentage of irrigated land in NC counties where data with available data for 2007, 2012, and 2017.

```{r bar chart}
ggplot(nc_irrigated) +
  geom_col(aes(x = year, y = percent_irrigated), fill = "grey50") +
  facet_wrap(~county_name) +
  xlab("Year") +
  ylab("Percent of Total Acres Irrigated (%)") +
  theme_bw()
```

We can plot just the counties that have all three years of data available.

```{r bar chart select}
# select counties that have all three years
nc_irrigated_mult_years <- nc_irrigated %>%
  group_by(county_name) %>%
  filter(n()>2)

# plot
ggplot(nc_irrigated_mult_years) +
  geom_col(aes(x = year, y = percent_irrigated), fill = "grey50") +
  facet_wrap(~county_name) +
  xlab("Year") +
  ylab("Percent of Total Acres Irrigated (%)") +
  theme_bw()
```


Looking at this figure, it's hard to see any big patterns in the NASS irrigation data. We can summarize the total number of acres irrigated for all 13 counties using `summarize()`.

```{r irrigated summary}
nc_irrigated_summary <- nc_irrigated_mult_years %>%
  group_by(year) %>%
  summarize(sum_irrigated_ac = sum(irrigated),
            sum_all_production_ac = sum(all_production_practices)) %>%
  mutate(percent_irrigated = (sum_irrigated_ac/sum_all_production_ac) * 100)

nc_irrigated_summary
```

We see that these 13 counties irrigated about 7% of their land in production for 2007 and 2017.

Besides making some bar charts we can also map the irrigation percentages by county. For now, we'll just filter out the 2017 data for this visualization.

```{r filter 2017 data}
nc_irrigated_2017 <- nc_irrigated %>%
  filter(year == 2017)
```

Next we'll use the `get_acs()` function in the `tidycensus` package with `geometry = TRUE` to download the [TIGER](https://www.census.gov/geo/maps-data/data/tiger.html) county boundaries shape (.shp) file for NC. The variable used here (i.e., "B19013_001") represents median income but you can use any variable you wish. We're mostly just interested in the spatial data associated with this and will ignore the tabular (i.e., median income) data.

```{r get acs shp}
nc_counties <- get_acs(geography = "county", state = "NC", variables = "B19013_001", year = 2017, geometry = TRUE, survey = "acs5")
```

The second last step is to join `nc_irrigated_2017` to the county boundary spatial data.

```{r join tab data to acs}
nc_irrigated_map_2017 <- left_join(nc_counties, nc_irrigated_2017, by = "GEOID")
```

Now we'll use `mapview()` to make an interactive plot where counties are colored based on the percentage of irrigated land. You can hover your mouse over the counties to see the actual percentages.

```{r}
mapviewOptions(vector.palette = colorRampPalette(c("snow", "darkblue", "grey10")))
mapview(nc_irrigated_map_2017, zcol = "percent_irrigated", legend = FALSE)
```

<br/>
Some other thoughts that I wanted to mention before signing off:

- Querying the NASS API was fairly straightforward, and despite needing to do some considerable data wrangling with the output, the `tidyverse` packages (i.e., `dplyr` and `tidyr`) helped a lot. I should note that I spent some time figuring out what the query outputs would look like for different commodities and what aspects of the query outputs I needed.

- It was interesting to see that a higher percentage of acres were irrigated in NC in 2007 compared to 2012. I can't say what caused these differences based on these data alone, but it would be interesting to look into whether this finding was linked to the 2007 drought. According to other scientists who lived and researched water resources at the time, [the 2007 drought affected millions of people in NC](http://climate.ncsu.edu/climateblog?id=161). A longer time series of irrigated land might help with this as would overlapping these county level results with drought reports and crop losses.

I can think of a number of other commodities that might be interesting to look at in the NASS Quick Stats data set. I'm assuming that some commonly farmed commodities (i.e., corn) might have more years and locations available. If you've used the NASS API for other applications or have any other questions/ideas please let me know!

# Updates Since Posting

June 2019: Looks like NASS has officially published a `usdarnass` package to CRAN! You can read the package documentation [here](https://cran.r-project.org/web/packages/usdarnass/usdarnass.pdf). Looks like there are some nice look-up tables which might be very helpful.

January 2019: Since first posting this, [Julian Reyes suggested](https://twitter.com/julianjon/status/1082849177917317120) using Nicholas Potter's package called `rnassqs` to help automate the NASS API portion of this post. You can read more about the `rnassqs` package [here](https://github.com/potterzot/rnassqs). Note to self that I need to check it out!