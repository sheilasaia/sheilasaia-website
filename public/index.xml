<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>  on  </title>
    <link>/</link>
    <description>Recent content in   on  </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>APIs to the Rescue (&amp; the Census of Agriculture) Part 2</title>
      <link>/post/2020-06-30-nass-api-part2/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020-06-30-nass-api-part2/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;In a &lt;a href=&#34;https://sheilasaia.rbind.io/post/2019-01-04-nass-api/&#34;&gt;previous blog post&lt;/a&gt;, I discussed the use of application program interfaces (APIs) in R. Specifically, I focused on accessing data from the US Department of Agriculture’s National Agricultural Statistics Survey (NASS) Quick Stats API. Since I wrote that previous blog post in January 2019, several R packages that aid access to the NASS Quick Stats API have come to my attention. With these packages, it’s much easier to access NASS Quick Stats data using R! Specifically, you don’t have to manually explore data availability or manually tidy the data you’ve retrieved, which is what I had to do when determining how to download Quick Stats irrigation data for North Carolina (NC) and when defining variablds like &lt;code&gt;nc_irrigated&lt;/code&gt;, respectively, in that blog post back in January 2019.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goals-of-this-post&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goals of This Post&lt;/h1&gt;
&lt;p&gt;The main goal of this blog post is to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use an R package to download and plot Census of Agriculture data from the NASS Quick Stats API.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to &lt;a href=&#34;http://nelson.rbind.io/&#34;&gt;Natalie Nelson&lt;/a&gt; and Andrew Dau, who I thanked in my &lt;a href=&#34;https://sheilasaia.rbind.io/post/2019-01-04-nass-api/&#34;&gt;previous blog post&lt;/a&gt;, I would also like to thank &lt;a href=&#34;https://potterzot.com/&#34;&gt;Nicholas Potter&lt;/a&gt; at Washington State University for developing the &lt;code&gt;rnassqs&lt;/code&gt; package and responding to my questions. I’d also like to thank my collaborator &lt;a href=&#34;https://nksingh01.wixsite.com/nitinsingh&#34;&gt;Nitin Singh&lt;/a&gt; for developing interesting research questions that inspired me to streamline my R code.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;available-nass-api-packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Available NASS API Packages&lt;/h1&gt;
&lt;p&gt;As of the posting date of this blog, there are three main packages to help R users interface with the NASS Quick Stats API:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;rnassqs&lt;/code&gt; - This package was developed in 2015 by &lt;a href=&#34;https://potterzot.com/&#34;&gt;Nicholas Potter&lt;/a&gt; at Washington State University and is supported by &lt;a href=&#34;https://ropensci.org/&#34;&gt;rOpenSci&lt;/a&gt;. To read more about this package, see examples, submit issues/bugs, and contribute to development see &lt;a href=&#34;https://github.com/ropensci/rnassqs&#34;&gt;here&lt;/a&gt;. This package is available on CRAN and you can read the manual &lt;a href=&#34;https://cran.r-project.org/web/packages/rnassqs/rnassqs.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;usdarnass&lt;/code&gt; - This package was developed in 2018 by &lt;a href=&#34;https://www.robertdinterman.com/&#34;&gt;Robert Dinterman&lt;/a&gt; at The Ohio State University. To read more about this package, see examples, submit issues/bugs, and contribute to development see &lt;a href=&#34;https://github.com/rdinter/usdarnass&#34;&gt;here&lt;/a&gt;. This package is available on CRAN and you can read the manual &lt;a href=&#34;https://cran.r-project.org/web/packages/usdarnass/usdarnass.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;rnass&lt;/code&gt; - This package was developed in 2015 by &lt;a href=&#34;http://eremrah.com/&#34;&gt;Emrah Er&lt;/a&gt; at Ankara University. To read more about this package, see examples, submit issues/bugs, and contribute to development see &lt;a href=&#34;https://github.com/emraher/rnass&#34;&gt;here&lt;/a&gt;. This package is not available on CRAN, so it would have to be installed via GitHub.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In this post, I’ll present code that uses the &lt;code&gt;rnassqs&lt;/code&gt; package only. However, I think it would be interesting to write a third blog post that compares all three R packages!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;set-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Set Up&lt;/h1&gt;
&lt;p&gt;First let’s load the R libraries that we’ll need to run the code in this blog post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidycensus)
library(tidyverse)
library(mapview)
library(rnassqs)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;tidycensus&lt;/code&gt;, &lt;code&gt;tidyverse&lt;/code&gt;, &lt;code&gt;mapview&lt;/code&gt; packages should all be familiar from my &lt;a href=&#34;https://sheilasaia.rbind.io/post/2019-01-04-nass-api/&#34;&gt;previous blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;rnassqs&lt;/code&gt; package is new to this blog post. It will help us look up available data on the NASS Quick Stats API and access it.&lt;/p&gt;
&lt;div id=&#34;census-api-set-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Census API Set Up&lt;/h2&gt;
&lt;p&gt;As I mentioned in my &lt;a href=&#34;https://sheilasaia.rbind.io/post/2019-01-04-nass-api/&#34;&gt;previous blog post&lt;/a&gt;, many APIs require that you have a personal API key to access the data stored within them. To run the code in this post you’ll need to make sure you request a Census API key (see instructions below) and a NASS API key (see instructions also below). Once you have your API keys, keep them all in one safe spot. I recommend a text file somewhere rememberable on your (password protected) computer.&lt;/p&gt;
&lt;p&gt;To request a Census API key, you’ll have to go &lt;a href=&#34;https://api.census.gov/data/key_signup.html&#34;&gt;here&lt;/a&gt; and fill in your name and organization. Once you submit the key request, the US Census Bureau will email you a Census API key. This key is unique to the name and email you provided so be sure to keep it in a save place.&lt;/p&gt;
&lt;p&gt;If you’ve never installed your Census API key in your R session, you’ll want to install your API key for later use.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;CENSUS_API_KEY &amp;lt;- &amp;quot;YOUR API KEY GOES HERE&amp;quot;
census_api_key(CENSUS_API_KEY, install = TRUE)

# The second line of code above will make an entry in your .Renviron file called &amp;quot;CENSUS_API_KEY&amp;quot;.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’ve already installed your Census API key, you should be good to go, but you can always check to make sure it’s in your R environment using the code below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set it in your .Renviron file
Sys.setenv(CENSUS_API_KEY = CENSUS_API_KEY)

# check that it&amp;#39;s there
Sys.setenv(&amp;quot;CENSUS_API_KEY&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to get tabular &lt;em&gt;and&lt;/em&gt; spatial census data using the &lt;code&gt;tidycensus&lt;/code&gt; package, you will need to run the code below each time you start a new R session. Spatial census data includes, for example, census tract boundaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;options(tigris_use_cache = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;nass-api-set-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;NASS API Set Up&lt;/h2&gt;
&lt;p&gt;Be sure to also apply for a NASS API key. We’ll use this later but will define it here as a string called &lt;code&gt;NASS_API_KEY&lt;/code&gt;. You can apply for a NASS API key &lt;a href=&#34;https://quickstats.nass.usda.gov/api&#34;&gt;here&lt;/a&gt;. As with the Census API key, this is unique you so be sure to keep it in a save place.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NASS_API_KEY &amp;lt;- &amp;quot;ADD YOUR NASS API KEY HERE&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to save your NASS API key to your R environment, you can use the code below. Setting the NASS API key in your R environment will keep it hidden and accessible only to you. This might be important if you’re planning to pass along your script to someone else…or post it on your blog. ;) Note, you would have to do this each time you open R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Sys.setenv(NASS_API_KEY = NASS_API_KEY)

# To check that it is there, use this code:
Sys.getenv(&amp;quot;NASS_API_KEY&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To use your NASS API in code later on call it and assign it to a variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NASS_API_KEY &amp;lt;- Sys.getenv(&amp;quot;NASS_API_KEY&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to be very organized and secure you can add your NASS API key to your .Renviron file. You will only need to do this once and then R will automatically load the key into your working environment whenever you start a new R session. If you’re interested in doing this and not too afraid of the command line, checkout &lt;a href=&#34;https://stackoverflow.com/questions/40788645/how-to-create-renviron-file&#34;&gt;this stackoverflow post&lt;/a&gt;. Note, that if you have already run &lt;code&gt;census_api_key()&lt;/code&gt; you will not need to make a new .Renviron file. It will already exist in your HOME directory.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;api-data-query&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;API Data Query&lt;/h1&gt;
&lt;p&gt;Now, we’ll define the NASS url and path. In the path you’ll have to specify what type of data you want to query. To specify these you can go to &lt;a href=&#34;https://quickstats.nass.usda.gov/&#34;&gt;https://quickstats.nass.usda.gov/&lt;/a&gt; to see all your commodity options. I haven’t figured out another way to do this but please &lt;a href=&#34;mailto:ssaia@ncsu.edu&#34;&gt;contact me&lt;/a&gt; if you find an alternative.&lt;/p&gt;
&lt;p&gt;For this post I’m selecting the “AG_LAND” commodity, which includes information on the acreage of irrigated farm and ranch lands, because this is the wateR blog after all. Other commodities might include specific crops, etc. I’m also selecting the state of North Carolina (NC) because it seems to always be the subject of spatial mapping &lt;a href=&#34;https://r-spatial.github.io/sf/reference/geos_combine.html&#34;&gt;(e.g., see this post)&lt;/a&gt; in R and is also where I live. ;) You can also leave off the last “&amp;amp;state_alpha=NC” part of the string to get data from all states.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# NASS url
nass_url &amp;lt;- &amp;quot;http://quickstats.nass.usda.gov&amp;quot;

# commodity description of interest
my_commodity_desc &amp;lt;- &amp;quot;AG LAND&amp;quot;

# short description of interest (i.e., &amp;#39;data item&amp;#39; on NASS Quick Stats website)
my_short_desc1 &amp;lt;- &amp;quot;AG LAND, IRRIGATED - ACRES&amp;quot;
my_short_desc2 &amp;lt;- &amp;quot;AG LAND - ACRES&amp;quot;

# query start year
my_year &amp;lt;- &amp;quot;2007&amp;quot;

# state of interest
my_state &amp;lt;- &amp;quot;NC&amp;quot;

# final path string
path_nc_irrig_land &amp;lt;- paste0(&amp;quot;api/api_GET/?key=&amp;quot;, NASS_API_KEY, &amp;quot;&amp;amp;commodity_desc=&amp;quot;, my_commodity_desc, &amp;quot;&amp;amp;short_desc=&amp;quot;, my_short_desc1, &amp;quot;&amp;amp;short_desc=&amp;quot;, my_short_desc2, &amp;quot;&amp;amp;year__GE=&amp;quot;, my_year, &amp;quot;&amp;amp;state_alpha=&amp;quot;, my_state)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s query the NASS API.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;raw_result_nc_irrig_land &amp;lt;- GET(url = nass_url, path = path_nc_irrig_land)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can check to see if it worked by looking at &lt;code&gt;status_code&lt;/code&gt;. To read more about the different status codes and their meaning you can visit &lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_HTTP_status_codes&#34;&gt;https://en.wikipedia.org/wiki/List_of_HTTP_status_codes&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;raw_result_nc_irrig_land$status_code&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great! We’re wanting to see status code 200 here. It means our query was received and responded to.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reformatting-api-query-output&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reformatting API Query Output&lt;/h1&gt;
&lt;p&gt;If we look at this in your R session it will come in as a ‘Large response’ or in other words as a JSON object. For simplicity sake, we can think of this as a list of lists (i.e., nested lists). We’ll ultimately convert this to a data frame because it’s a little easier to view in R.&lt;/p&gt;
&lt;p&gt;We’ll start unpacking the JSON object using &lt;code&gt;rawToChar()&lt;/code&gt;. We can check the size and look at the first few characters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;char_raw_nc_irrig_land &amp;lt;- rawToChar(raw_result_nc_irrig_land$content)

# check size of object
nchar(char_raw_nc_irrig_land)

# view first 50 characthers
substr(char_raw_nc_irrig_land, 1, 50)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is still a little hard to work with so let’s use &lt;code&gt;fromJSON()&lt;/code&gt; and convert the raw character strings to a large list. Due to recent (early 2020) updates to NASS, they now have the data saved in a “data” element of the JSON output.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_raw_nc_irrig_land &amp;lt;- fromJSON(char_raw_nc_irrig_land)

# keep data element
nc_irrig_land_raw_data &amp;lt;- list_raw_nc_irrig_land$data

# look at the data frame
head(nc_irrig_land_raw_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This looks ok but there are still some things that would be nice to clean up. As mentioned above, we want to focus on the acres of irrigated lands in NC. For simplicity, we’ll just look at farms/ranches with 2,000 ac or more under operation. Let’s step through each line in the piped (i.e., &lt;code&gt;%&amp;gt;%&lt;/code&gt;) code below. See the in-line comments for the details.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nc_irrigated &amp;lt;- nc_irrig_land_raw_data %&amp;gt;%
  
  # filter to select county level irrigation data where farms/ranches with 2,000+ ac operation and irrigation status to get total acres of ag land in county
  filter(agg_level_desc == &amp;quot;COUNTY&amp;quot;) %&amp;gt;%
  filter(unit_desc == &amp;quot;ACRES&amp;quot;) %&amp;gt;%
  filter(domaincat_desc == &amp;quot;AREA OPERATED: (2,000 OR MORE ACRES)&amp;quot; | domaincat_desc == &amp;quot;IRRIGATION STATUS: (ANY ON OPERATION)&amp;quot;) %&amp;gt;%

  # trim white space from ends (note: &amp;#39;Value&amp;#39; is a character here, not a number)
  mutate(value_trim = str_trim(Value)) %&amp;gt;%
  
  # select only the columns we&amp;#39;ll need
  select(state_name, state_alpha, state_ansi, county_code, county_name, asd_desc,
         agg_level_desc, year, prodn_practice_desc_char = prodn_practice_desc, domaincat_desc, 
         short_desc, value_ac_per_yr_char=value_trim, unit_desc) %&amp;gt;%
  
  # filter out entries with codes &amp;#39;(D)&amp;#39; and &amp;#39;(Z)&amp;#39;
  filter(value_ac_per_yr_char != &amp;quot;(D)&amp;quot; &amp;amp; value_ac_per_yr_char != &amp;quot;(Z)&amp;quot;) %&amp;gt;% 
  
  # remove commas from number values and convert to R numeric class
  mutate(value_ac_per_yr = as.numeric(str_remove(value_ac_per_yr_char, &amp;quot;,&amp;quot;))) %&amp;gt;%
  
  # change blanks to underscores in prodn_practice_desc_char for latter processing
  mutate(prodn_practice_desc = str_replace_all(str_to_lower(prodn_practice_desc_char),
                                               &amp;quot;[ ]&amp;quot;, &amp;quot;_&amp;quot;)) %&amp;gt;%
  
  # remove unnecessary columns
  select(-value_ac_per_yr_char, -prodn_practice_desc_char) %&amp;gt;%
  #arrange(county_code, year) 
  
  # we have 2007, 2012, and 2017 data and we want irrigated land acreage and total land acreage
  # (to calculate a percentage of irrigated land) so we use n()&amp;gt;1 to filter out counties
  # that have both types of acreage for each year
  group_by(county_code, year) %&amp;gt;%
  filter(n()&amp;gt;1) %&amp;gt;%
  
  # drop columns we don&amp;#39;t need
  select(-domaincat_desc, -short_desc) %&amp;gt;%
  
  # pivot wide irrigated and total lands operated data and calculate percent irrigated
  pivot_wider(names_from = prodn_practice_desc, values_from = value_ac_per_yr) %&amp;gt;%
  mutate(percent_irrigated = round(irrigated/all_production_practices*100, 1)) %&amp;gt;%
  
  # make a column with the county name and year (we&amp;#39;ll need this for plotting)
  mutate(county_year = paste0(str_to_lower(county_name), &amp;quot;_&amp;quot;, year)) %&amp;gt;%
  
  # make GEOID column to match up with county level spatial data (we&amp;#39;ll need this for mapping)
  mutate(GEOID = paste0(state_ansi, county_code)) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s look at the first few rows of the final reformatted NASS data showing the amount of irrigated acres in NC for 2007, 2012, and 2017.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(nc_irrigated)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-nass-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plotting NASS Data&lt;/h1&gt;
&lt;p&gt;Now that we have this nicely formatted data, we can make some figures! Let’s start by making some bar charts comparing the percentage of irrigated land in NC counties where data with available data for 2007, 2012, and 2017.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(nc_irrigated) +
  geom_col(aes(x = factor(year), y = percent_irrigated), fill = &amp;quot;grey50&amp;quot;) +
  facet_wrap(~county_name) +
  xlab(&amp;quot;Year&amp;quot;) +
  ylab(&amp;quot;Percent of Total Acres Irrigated (%)&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can plot just the counties that have all three years of data available.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# select counties that have all three years
nc_irrigated_mult_years &amp;lt;- nc_irrigated %&amp;gt;%
  group_by(county_name) %&amp;gt;%
  filter(n()&amp;gt;2)

# plot
ggplot(nc_irrigated_mult_years) +
  geom_col(aes(x = factor(year), y = percent_irrigated), fill = &amp;quot;grey50&amp;quot;) +
  facet_wrap(~county_name) +
  xlab(&amp;quot;Year&amp;quot;) +
  ylab(&amp;quot;Percent of Total Acres Irrigated (%)&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at this figure, it’s hard to see any big patterns in the NASS irrigation data. We can summarize the total number of acres irrigated for all 13 counties using &lt;code&gt;summarize()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nc_irrigated_summary &amp;lt;- nc_irrigated_mult_years %&amp;gt;%
  group_by(year) %&amp;gt;%
  summarize(sum_irrigated_ac = sum(irrigated),
            sum_all_production_ac = sum(all_production_practices)) %&amp;gt;%
  mutate(percent_irrigated = (sum_irrigated_ac/sum_all_production_ac) * 100)

nc_irrigated_summary&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that these 13 counties irrigated about 6.7% of their land in production for 2007 and 2017.&lt;/p&gt;
&lt;p&gt;Besides making some bar charts we can also map the irrigation percentages by county. For now, we’ll just filter out the 2017 data for this visualization.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nc_irrigated_2017 &amp;lt;- nc_irrigated %&amp;gt;%
  filter(year == 2017)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we’ll use the &lt;code&gt;get_acs()&lt;/code&gt; function in the &lt;code&gt;tidycensus&lt;/code&gt; package with &lt;code&gt;geometry = TRUE&lt;/code&gt; to download the &lt;a href=&#34;https://www.census.gov/geo/maps-data/data/tiger.html&#34;&gt;TIGER&lt;/a&gt; county boundaries shape (.shp) file for NC. The variable used here (i.e., “B19013_001”) represents median income but you can use any variable you wish. We’re mostly just interested in the spatial data associated with this and will ignore the tabular (i.e., median income) data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nc_counties &amp;lt;- get_acs(geography = &amp;quot;county&amp;quot;, state = &amp;quot;NC&amp;quot;, variables = &amp;quot;B19013_001&amp;quot;, year = 2017, geometry = TRUE, survey = &amp;quot;acs5&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second last step is to join &lt;code&gt;nc_irrigated_2017&lt;/code&gt; to the county boundary spatial data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nc_irrigated_map_2017 &amp;lt;- left_join(nc_counties, nc_irrigated_2017, by = &amp;quot;GEOID&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’ll use &lt;code&gt;mapview()&lt;/code&gt; to make an interactive plot where counties are colored based on the percentage of irrigated land. You can hover your mouse over the counties to see the actual percentages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mapviewOptions(vector.palette = colorRampPalette(c(&amp;quot;snow&amp;quot;, &amp;quot;darkblue&amp;quot;, &amp;quot;grey10&amp;quot;)))
# mapview(nc_irrigated_map_2017, zcol = &amp;quot;percent_irrigated&amp;quot;, legend = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br/&gt;
Some other thoughts that I wanted to mention before signing off:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Querying the NASS API was fairly straightforward, and despite needing to do some considerable data wrangling with the output, the &lt;code&gt;tidyverse&lt;/code&gt; packages (i.e., &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;tidyr&lt;/code&gt;) helped a lot. I should note that I spent some time figuring out what the query outputs would look like for different commodities and what aspects of the query outputs I needed.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It was interesting to see that a higher percentage of acres were irrigated in NC in 2007 compared to 2012. I can’t say what caused these differences based on these data alone, but it would be interesting to look into whether this finding was linked to the 2007 drought. According to other scientists who lived and researched water resources at the time, &lt;a href=&#34;http://climate.ncsu.edu/climateblog?id=161&#34;&gt;the 2007 drought affected millions of people in NC&lt;/a&gt;. A longer time series of irrigated land might help with this as would overlapping these county level results with drought reports and crop losses.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I can think of a number of other commodities that might be interesting to look at in the NASS Quick Stats data set. I’m assuming that some commonly farmed commodities (i.e., corn) might have more years and locations available. If you’ve used the NASS API for other applications or have any other questions/ideas please let me know!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;updates-since-posting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Updates Since Posting&lt;/h1&gt;
&lt;p&gt;June 2020: NASS updated the format of their database so the data is saved in a data element of the JSON list. Thus, this post no longer requires the &lt;code&gt;purrr&lt;/code&gt; package to run.&lt;/p&gt;
&lt;p&gt;June 2019: Looks like NASS has officially published a &lt;code&gt;usdarnass&lt;/code&gt; package to CRAN! You can read the package documentation &lt;a href=&#34;https://cran.r-project.org/web/packages/usdarnass/usdarnass.pdf&#34;&gt;here&lt;/a&gt;. Looks like there are some nice look-up tables which might be very helpful.&lt;/p&gt;
&lt;p&gt;January 2019: Since first posting this, &lt;a href=&#34;https://twitter.com/julianjon/status/1082849177917317120&#34;&gt;Julian Reyes suggested&lt;/a&gt; using Nicholas Potter’s package called &lt;code&gt;rnassqs&lt;/code&gt; to help automate the NASS API portion of this post. You can read more about the &lt;code&gt;rnassqs&lt;/code&gt; package &lt;a href=&#34;https://github.com/potterzot/rnassqs&#34;&gt;here&lt;/a&gt;. Note to self that I need to check it out!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Critical Review of Polyphosphate and Polyphosphate Accumulating Organisms for Agricultural Water Quality Management</title>
      <link>/publication/pao_review/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 -0400</pubDate>
      
      <guid>/publication/pao_review/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tidy Spatial Data in R</title>
      <link>/talk/duke_mar2020/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 -0500</pubDate>
      
      <guid>/talk/duke_mar2020/</guid>
      <description>

&lt;h2 id=&#34;description-br&#34;&gt;Description:&lt;/br&gt;&lt;/h2&gt;

&lt;p&gt;In this guest lecture for Environmental Data Analytics (ENV 872) at Duke University, I covered the basics of using the sf package in R. Dr. Kateri Salk taught the first day (March 3, 2020) of my lesson and I finished up by teaching the second day (March 5, 2020).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://nicholas.duke.edu/academics/courses/environmental-data-analytics&#34; target=&#34;_blank&#34;&gt;Click here for background on the Environmental Data Analytics (ENV 872) course.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;Click here for the course GitHub repository.&#34; target=&#34;_blank&#34;&gt;Click here for the course GitHub repository.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Environmental Data Science Panel</title>
      <link>/talk/duke_apr2020/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 -0500</pubDate>
      
      <guid>/talk/duke_apr2020/</guid>
      <description>

&lt;h2 id=&#34;description-br&#34;&gt;Description:&lt;/br&gt;&lt;/h2&gt;

&lt;p&gt;In this remote panel event for Geospatial Analysis for Conservation Management (ENV 761) at Duke University, I was one of three invited environmental data science panelists. We discussed how we use data science in our current position and also responded to questions from the class.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Data Management Plans for Researchers</title>
      <link>/talk/ncsu_feb2020/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 -0500</pubDate>
      
      <guid>/talk/ncsu_feb2020/</guid>
      <description>

&lt;h2 id=&#34;description-br&#34;&gt;Description:&lt;/br&gt;&lt;/h2&gt;

&lt;p&gt;Data management is an overlooked yet important research skill, especially since nearly all major federal funding agencies in the United States require researchers to include a data management plan along with their grant application. If you’re preparing a data management plan, looking for ways to improve an existing data management plan, or want to learn more about data management plans, this workshop is for you. Postdoctoral researcher, Sheila Saia, will lead workshop attendees through the basics of data management plans including: what they are, why they’re important, and their major components. Attendees will also gain hands-on experience in building a data management plan for their own research using the DMPTool (&lt;a href=&#34;https://dmptool.org/&#34; target=&#34;_blank&#34;&gt;https://dmptool.org/&lt;/a&gt;). At the end of the workshop, attendees will learn about general data management best practices that may help them take additional steps to more efficient and more reproducible research. Bring along your laptop or use one of the laptops available at the Libraries!&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.lib.ncsu.edu/workshops/introduction-data-management-plans-researchers&#34; target=&#34;_blank&#34;&gt;Click here to view event information. &lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using R and Python to Map Vulnerable Communities and Future Streamflow</title>
      <link>/talk/duke_feb2020/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 -0500</pubDate>
      
      <guid>/talk/duke_feb2020/</guid>
      <description>

&lt;h2 id=&#34;description-br&#34;&gt;Description:&lt;/br&gt;&lt;/h2&gt;

&lt;p&gt;In this guest lecture for Geospatial Analysis for Conservation Management (ENV 761) at Duke University, I gave an overview of how and why I use R and Python for geospatial analysis. I highlighted my how I&amp;rsquo;ve used R and Python in some &lt;a href=&#34;https://sheilasaia.rbind.io/project/nc-sociohydro-project/&#34; target=&#34;_blank&#34;&gt;recent work&lt;/a&gt; in western North Carolina. Last, I led a discussion of a &lt;a href=&#34;https://www.fs.usda.gov/treesearch/pubs/58292&#34; target=&#34;_blank&#34;&gt;recenlty published paper&lt;/a&gt; associated with this work.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://nicholas.duke.edu/academics/courses/geospatial-analysis-conservation-management&#34; target=&#34;_blank&#34;&gt;Click here for background on the Geospatial Analysis for Conservation Management (ENV 761) course.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improved Accuracy of Watershed-Scale General Circulation Model Runoff Using Deep Neural Networks</title>
      <link>/publication/dnn-validation/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 -0500</pubDate>
      
      <guid>/publication/dnn-validation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine Learning Applications in Hydrology</title>
      <link>/project/streamflow-ml-project/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 -0500</pubDate>
      
      <guid>/project/streamflow-ml-project/</guid>
      <description>

&lt;h1 id=&#34;collaborators&#34;&gt;Collaborators&lt;/h1&gt;

&lt;p&gt;JS Rice, JM Vose, and RE Emanuel&lt;/p&gt;

&lt;h1 id=&#34;timeline&#34;&gt;Timeline&lt;/h1&gt;

&lt;p&gt;2019-2020&lt;/p&gt;

&lt;h1 id=&#34;project-goal&#34;&gt;Project Goal&lt;/h1&gt;

&lt;p&gt;The goal of this project was to use machine learning models for two applications in hydrology. First, we used a hierarchical machine learning ensemble model to predict streamflow. Then, we assessed model sensitivies to learn how changes in the percentage of different types of land cover in specific places in the watershed influenced (i.e., increase or decrease) streamflow. Second, we trained and tested a deep neural network (DNN) to convert downscaled, gridded General Circulation Model (GCM) hydroclimatic fluxes to watershed-scale runoff for over 2,700 watersheds across the conterminous United States. We also compared DNN performance to several other emperical grid-to-watershed-scale conversion methods.&lt;/p&gt;

&lt;h1 id=&#34;project-links&#34;&gt;Project Links&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://eartharxiv.org/awqjg/&#34; target=&#34;_blank&#34;&gt;Deep Neural Network preprint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h1&gt;

&lt;p&gt;Thanks to the National Science Foundation and the US Forest Service for supporting this research.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improved Accuracy of Watershed-Scale General Circulation Model Runoff Using Deep Neural Networks (Poster #GC43D-1361)</title>
      <link>/talk/agu_dec2019/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 -0500</pubDate>
      
      <guid>/talk/agu_dec2019/</guid>
      <description>

&lt;h2 id=&#34;abstract-br&#34;&gt;Abstract:&lt;/br&gt;&lt;/h2&gt;

&lt;p&gt;Projecting future climate change impacts on water resources is a vital research task and general circulation models (GCMs) help researchers achieve this goal. However, the spatial resolution of downscaled GCMs (e.g., 1.4° grid) makes them difficult to apply to non-grid conforming scales relevant to water resources management: individual watersheds. Machine learning techniques such as deep neural networks (DNNs) may address this issue by downscaling GCM data without a priori specification of complex hydrologic processes in a watershed. Here, we use a DNN to predict monthly watershed-scale runoff (i.e., stream discharge divided by watershed area) from monthly, gridded, downscaled, Coupled Model Intercomparison Project Phase 5 GCM hydrologic fluxes (i.e., precipitation, evapotranspiration, and temperature). We trained the DNN on a subset of observed hydrologic fluxes and watershed characteristics from 2,731 watersheds in the continental United States and tested its ability to predict observed runoff using the remaining data. The DNN described 94% of the variability in observed runoff and was spatially and temporally robust. DNN runoff predictions were nearly twice as accurate as raw, monthly, gridded, downscaled GCM runoff and had the lowest mean absolute error of other grid-to-watershed-scale conversion techniques, including: long-term monthly mean climatology, linear least squares, lasso, support vector machine, extreme gradient boosting, and simple artificial neural network approaches. This study serves as a guide to hydrologists interested in implementing machine learning techniques and also demonstrates how DNNs can be used to convert gridded GCM hydrologic fluxes to scales more relevant to water resources research and management.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://agu.confex.com/agu/fm19/meetingapp.cgi/Paper/499522&#34; target=&#34;_blank&#34;&gt;Click here to view my AGU abstract. &lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R-Ladies Global: Promoting Diversity and Inclusion in the R Community (Poster #ED33G-1047)</title>
      <link>/talk/agu_dec2019_rladies/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 -0500</pubDate>
      
      <guid>/talk/agu_dec2019_rladies/</guid>
      <description>

&lt;h2 id=&#34;abstract-br&#34;&gt;Abstract:&lt;/br&gt;&lt;/h2&gt;

&lt;p&gt;R-Ladies Global is a worldwide organization focused on achieving proportionate representation of genders currently underrepresented in the R programming community. To meet this goal, we support a network of local chapters who organize events that encourage, inspire, and empower individuals to meet their programming potential. Since R-Ladies Global was founded in 2016, it has grown to provide training and mentoring to in over 47,000 members, in 159 cities, and 47 countries. Local chapters have held over 1,500 events focused on a wide range of topics from workshops on popular R programming libraries (e.g., ggplot, Shiny) to data science panels on various topics (e.g., Ethics in Data Science, Women in Tech) to hackathons (e.g., #TidyTuesday) to speaking opportunities (e.g., Lightning Talks) to networking events (e.g., dinner meet-ups, book clubs). There are many leadership, training, career development, and mentoring opportunities for early career scientists who join R-Ladies Global. Please stop by our poster or visit our website (&lt;a href=&#34;https://rladies.org/about-us&#34; target=&#34;_blank&#34;&gt;https://rladies.org/about-us&lt;/a&gt;) to learn more about how you can get involved and/or support our mission.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://agu.confex.com/agu/fm19/meetingapp.cgi/Paper/490269&#34; target=&#34;_blank&#34;&gt;Click here to view my AGU abstract. &lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mapping Vulnerable Communities and Streamflow Projections to Aid Climate Change Adaptation Planning</title>
      <link>/talk/meas-oct2019/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 -0400</pubDate>
      
      <guid>/talk/meas-oct2019/</guid>
      <description>

&lt;h2 id=&#34;bio-br&#34;&gt;Bio:&lt;/br&gt;&lt;/h2&gt;

&lt;p&gt;Sheila Saia received her BS in Bioengineering from Binghamton University and her MS and PhD degrees in Biological and Environmental Engineering at Cornell University. She is a postdoctoral researcher in NC State University’s Department of Forestry and Environmental Resources and an affiliate of the USDA Forest Service Southern Research Station in RTP. Her current postdoctoral research links hydrologic model (i.e., Soil and Water Assessment Tool; SWAT) results and United States Census data to aid climate change adaptation planning in North Carolina. Sheila has experience using model-, laboratory-, and field-based research to improve water quantity and water quality.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Let&#39;s Talk About Water: Lost Waterways of Winston-Salem</title>
      <link>/talk/ltaw_sept2019/</link>
      <pubDate>Tue, 20 Aug 2019 00:00:00 -0400</pubDate>
      
      <guid>/talk/ltaw_sept2019/</guid>
      <description>

&lt;h2 id=&#34;abstract-br&#34;&gt;Abstract:&lt;/br&gt;&lt;/h2&gt;

&lt;p&gt;The Lost Waterways of Winston-Salem is a free film screening and panel discussion at &lt;a href=&#34;https://www.aperturecinema.com/f-aq/&#34; target=&#34;_blank&#34;&gt;a/perture cinema&lt;/a&gt;. Drawing on the Winston-Salem motto of the &amp;ldquo;City of Arts and Innovation,&amp;rdquo; this event seeks to engage students and community members in a conversation about local water issues by highlighting the connection between STEM and the arts. Beginning at 5:00 PM, all are invited to the Chatham Building Atrium (305 W. 4th St.) to enjoy refreshments, engage with community partners, and explore environmentally-themed artwork by local artists. The screening of &lt;a href=&#34;https://www.imdb.com/title/tt2421498/&#34; target=&#34;_blank&#34;&gt;Lost Rivers (2012)&lt;/a&gt; will begin at 6pm in a/perture studios 1 &amp;amp; 2. Immediately following the screening, expert panelists will engage in a discussion moderated by Linda Lilienfeld, the &lt;a href=&#34;http://letstalkaboutwater.com/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Let&amp;rsquo;s Talk about Water&amp;rdquo;&lt;/a&gt; Founder and Project Coordinator. Panelists include: Dr. Lauren Lowman, Dr. Sheila Saia, Kristen Ford Haaf, and Christine Rucker.&lt;/p&gt;

&lt;p&gt;To read more and RSVP for this free event, visit &lt;a href=&#34;https://www.eventbrite.com/e/lost-waterways-of-winston-salem-film-screening-panel-discussion-tickets-65981950791&#34; target=&#34;_blank&#34;&gt;this website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/lost_waterways_2019.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Intro to Preprints for Early Career Hydrologists</title>
      <link>/post/2019-05-19-preprint-intro/</link>
      <pubDate>Mon, 20 May 2019 21:12:00 -0500</pubDate>
      
      <guid>/post/2019-05-19-preprint-intro/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;When I attended the 2019 &lt;a href=&#34;https://sites.agu.org/&#34;&gt;American Geophysical Union (AGU)&lt;/a&gt; this past December in Washington, DC, I had the pleasure of meeting members of an international organization of early career hydrologists called the &lt;a href=&#34;https://younghs.com/&#34;&gt;Young Hydrologic Society (YHS)&lt;/a&gt;. To clarify, “young” here refers to early career, rather than age. I was interested in getting more involved in the organization and thought writing a blog post for the group’s website would be a great way for me to contribute. I had recently lead a discussion on preprints with peers back in North Carolina and thought a blog post on this topic would be a perfect opportunity to continue that discussion. I also had (and still have) a lot of questions regarding preprints and hoped that preparing the blog post would give the opportunity to answer these questions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goals-of-this-post&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goals of This Post&lt;/h1&gt;
&lt;p&gt;The blog post that follows is re-posted of the YHS article I wrote on preprints. You can find the original article &lt;a href=&#34;https://younghs.com/2019/05/20/an-introduction-to-preprints-for-early-career-hydrologists/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thanks to H. Beria, C. Hall, S. Harrigan, C. Jackson, and N. Krell for their helpful feedback on this post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Growing calls for open and reproducible research across science, technology, engineering, and math (STEM) disciplines have advanced the conversation around preprints (e.g., Schloss, 2017; Narock et al., 2019). Early Career Hydrologists may benefit from considering and discussing the role of preprints in shaping scientific discovery and career trajectories. Here we introduce preprints, offering Early Career Hydrologists with a variety of thoughts on the advantages and disadvantages of using preprints in research workflows, and providing tips and resources for learning more. If we missed an aspect of the preprint discussion that you feel passionate about or still have questions about, please feel free to reach out to Sheila (at &lt;a href=&#34;https://twitter.com/sheilasaia?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor&#34;&gt;sheilasaia&lt;/a&gt;) and the Young Hydrology Society (YHS; at &lt;a href=&#34;https://twitter.com/younghydrology?lang=en&#34;&gt;YoungHydrology&lt;/a&gt;) on Twitter.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-a-preprint&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is a preprint?&lt;/h1&gt;
&lt;p&gt;A preprint refers to a research product (typically a research article) that is made publicly available before or at the same time it goes to peer review. A preprint server refers to an open access website where authors can submit and manage versions of their preprints.&lt;/p&gt;
&lt;p&gt;Some preprint servers such as European Geophysical Union (EGU) sponsored &lt;a href=&#34;https://www.hydrol-earth-syst-sci-discuss.net/discussion_papers.html&#34;&gt;Hydrology and Earth Systems Science (HESS) Discussions&lt;/a&gt; is affiliated with EGU’s HESS journal. Additionally, the American Geophysical Union (AGU) sponsored Earth and Space Science Open Archive (ESSOAr) preprint server is associated with AGU-affiliated journals. These journal-supported preprint servers offer a convenient publishing pipeline should the author’s work be accepted after peer review.&lt;/p&gt;
&lt;p&gt;Other preprint servers are not affiliated with a particular journal (e.g., &lt;a href=&#34;https://eartharxiv.org/&#34;&gt;EarthArXiv&lt;/a&gt;, and &lt;a href=&#34;https://www.biorxiv.org/&#34;&gt;bioRxiv&lt;/a&gt;). If an authors’ article is accepted for publication to a partner journal, these servers may offer transfer services for authors. For example, the bioRxiv offers transfer services to several journals including Applied and Environmental Microbiology (see details &lt;a href=&#34;https://www.biorxiv.org/about-biorxiv&#34;&gt;here&lt;/a&gt;). Preprint servers are typically not-for-profit (e.g., arXiv, bioRxiv, EarthArXiv); it is always good to check a preprint server’s not-for-profit status before submitting a preprint. See the ‘Things to Consider before Sharing a Preprint’ discussion below for more information.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;advantages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Advantages:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Depending on the preprint server, authors may be given a digital object identifier (DOI) number that can be used to cite their work. Also, the preprint server manages the storage and versions of the preprint free of charge. The DOI allows others to cite, and ultimately, give authors credit for their ideas and work.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The preprint (and eventually a postprint, if accepted by a journal) can be shared more broadly. This is especially true of the final publication, since a journal subscription is not required.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Preprints improve the transparency of the peer review process by enabling readers to view article versions at each step of the review process; and thus, assess changes they’ve made.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Preprint servers enable discussions between authors and interested parties. Readers can contribute to and look through these discussions via preprint server commenting features and direct communication with authors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Posting a preprint allows author to share so-called ‘negative results’, which may improve future studies and conserve future time and funding resources (van Emmerik et al. 2018)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Preprints may help streamline collaborations by avoiding or improving studies in different locations that address similar research goals.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Preprint servers empower scientists to take control of the timeline for making their results public (Schloss 2017). This might prove especially helpful to overcoming current limitations of peer review (e.g., gender bias; Grogan 2019).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Preprints can help facilitate research findings to the public domain, so as to stimulate interactions and collaborations with fellow researchers. This may be especially helpful for Earth Career Scientists looking for potential collaborators inside and outside of their field.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Earth Career Scientists may be able to use preprints in grant and job applications to present progress and preliminary results. For example, the US National Institutes of Health allows scientists to include preprints in grant proposals (Kaiser 2017a, 2017b).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Some disciplines (e.g., physics) use preprint servers to stake claim to their results (or at least have a DOI associated with their early work).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;disadvantages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Disadvantages:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The discussion of preprint disadvantages largely centers around the fact that preprints are not validated by peer review (Kaiser 2017b). Researchers can make claims, which may be cited by others, without valid data supporting those claims. This may become especially problematic at the interface of science and the general public, especially if the general public and media representatives do not understand that the preprint is not peer reviewed.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Another common criticism of preprints centers around fear of being “scooped”—when an author’s work is stolen before it can be published. [On the other hand, authors of preprints have a DOI. Also, some journals have announced “scooping protection” (Kaiser 2017b).]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Researchers that post preprints need to do their homework before making their work public. See the ‘Things to Consider before Sharing a Preprint’ discussion below. Most notably, it is important that authors know what their journal-of-choice’s preprint policies are in terms of accepting preprints, type of preprint licenses, and preprint server funding structures (i.e., not-for-profit) that are allowed.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;things-to-consider-before-sharing-a-preprint&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Things to Consider Before Sharing a Preprint&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Check whether the journal you are planning to submit your work to accepts preprints. You can check a journal’s preprint policy on &lt;a href=&#34;http://www.sherpa.ac.uk/romeo/index.php&#34;&gt;SHERPA/RoMEO&lt;/a&gt;. Many journals accept preprints posted on not-for-profit preprint servers, but it is best to confirm that this is the case. When in doubt, you can email the editor to clarify the journal’s preprint policy. In addition to the funding structure of the preprint server (e.g., not-for-profit), be sure to pay attention to the journal’s policies related to licenses that are assigned by the preprint servers (e.g., CC BY).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ask your co-authors for permission to post your article as a preprint, which includes asking them about their institution’s or company’s preprint policy. Before you post, you want to make sure everyone agrees to post your article as a preprint.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Make sure your article is ready to be posted as a preprint. Once your preprint is in the public domain, it will be very hard to remove.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;where-can-i-post-andor-read-a-hydrology-preprint&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Where can I post and/or read a hydrology preprint?&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://arxiv.org/&#34;&gt;arXiv&lt;/a&gt; is the oldest preprint server to-date (since 1991) and hosts research from physics, mathematics, computer science, statistics, engineering, and various other disciplines that interface with the hydrologic sciences. As of May 2019 (when this post was written), there were 241 arXiv search results for “hydrology” (0.02% of the entire collection).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inspired by the arXiv, researchers established the &lt;a href=&#34;https://eartharxiv.org/&#34;&gt;EarthArXiv&lt;/a&gt; in 2017 to serve the earth sciences community; thus, hydrology is particularly well represented here. EarthArXiv is part of the &lt;a href=&#34;https://osf.io/&#34;&gt;Open Science Framework (OSF)&lt;/a&gt; initiative.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Last but not least, the &lt;a href=&#34;https://www.essoar.org/&#34;&gt;Earth and Space Science Open Archive (ESSOAr)&lt;/a&gt; preprint server was established in 2018 through a joint effort with the American Geophysical Union (AGU) and &lt;a href=&#34;https://www.atypon.com/&#34;&gt;Atypon&lt;/a&gt;. ESSOAr is especially well suited for research that will be submitted to AGU-affiliated journals.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;can-and-how-do-i-cite-a-preprint&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Can (and how do) I cite a preprint?&lt;/h1&gt;
&lt;p&gt;As mentioned above, preprints need to be treated as unpublished, non-peer reviewed publications. As an author and reader, you need to assess the validity and quality of the work before you cite a preprint. Before submitting an article that cites preprinted work, you should check that the journal allows preprint citations. If the journal allows preprints, authors should adhere to the formatting guidelines to make it clear to reviewers/readers that the work is not peer-reviewed. The same goes for funding agencies. An example policy on how to cite preprints can be found for Nature-affiliated journals at &lt;a href=&#34;https://www.nature.com/authors/policies/preprints.html&#34; class=&#34;uri&#34;&gt;https://www.nature.com/authors/policies/preprints.html&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p&gt;Grogan, K. 2019. How the entire scientific community can confront gender bias in the workplace. Nature Ecology &amp;amp; Evolution. 3:3-6. Accessed online at: &lt;a href=&#34;https://www.nature.com/articles/s41559-018-0747-4&#34; class=&#34;uri&#34;&gt;https://www.nature.com/articles/s41559-018-0747-4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kaiser, J. 2017a. NIH enables investigators to include draft preprints in grant proposals. Science. Mar. 24, 2017. Accessed online at: &lt;a href=&#34;https://www.sciencemag.org/news/2017/03/nih-enables-investigators-include-draft-preprints-grant-proposals&#34; class=&#34;uri&#34;&gt;https://www.sciencemag.org/news/2017/03/nih-enables-investigators-include-draft-preprints-grant-proposals&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kaiser, J. 2017b. The preprint dilemma. Science. 357(6358):1344-1349. Available online at: &lt;a href=&#34;https://science.sciencemag.org/content/357/6358/1344&#34; class=&#34;uri&#34;&gt;https://science.sciencemag.org/content/357/6358/1344&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Narock, T., E. Goldstein, C. Jackson, A. Bubeck, A. Enright, J. Farquharson, et al. Earth Science is Ready for Preprints. Eos. Apr. 23, 2019. Available online at: &lt;a href=&#34;https://eartharxiv.org/kftsv/&#34; class=&#34;uri&#34;&gt;https://eartharxiv.org/kftsv/&lt;/a&gt; and &lt;a href=&#34;https://eos.org/project-updates/earth-science-is-ready-for-preprints&#34; class=&#34;uri&#34;&gt;https://eos.org/project-updates/earth-science-is-ready-for-preprints&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Schloss, P. D. 2017. Preprinting Microbiology. mbio. 8:e00438-17. Available online at: &lt;a href=&#34;https://mbio.asm.org/content/8/3/e00438-17&#34; class=&#34;uri&#34;&gt;https://mbio.asm.org/content/8/3/e00438-17&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;van Emmerik, T., A. Popp, A. Solcerova, H. Muller, and R. Hut. 2018. Reporting negative results to stimulate experimental hydrology: discussion of “The role of experimental work in hydrological sciences - insights from a community survey”. Hydrological Sciences Journal. 63:1269-1273. &lt;a href=&#34;https://doi.org/10.1080/02626667.2018.1493203&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1080/02626667.2018.1493203&lt;/a&gt;. Available online at: &lt;a href=&#34;https://eartharxiv.org/jhrfb/&#34; class=&#34;uri&#34;&gt;https://eartharxiv.org/jhrfb/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-reading-on-preprints&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Additional Reading on Preprints&lt;/h1&gt;
&lt;p&gt;Nature Geosciences (editorial). 2018. ArXives of Earth Science. Nature Geosciences. 11: 149. Available online at: &lt;a href=&#34;https://www.nature.com/articles/s41561-018-0083-y&#34; class=&#34;uri&#34;&gt;https://www.nature.com/articles/s41561-018-0083-y&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ESSOAr FAQs: &lt;a href=&#34;https://www.essoar.org/faq&#34; class=&#34;uri&#34;&gt;https://www.essoar.org/faq&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PLOS Preprint Resources: &lt;a href=&#34;https://www.plos.org/preprints&#34; class=&#34;uri&#34;&gt;https://www.plos.org/preprints&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-thoughts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Additional Thoughts&lt;/h1&gt;
&lt;p&gt;This post is meant to provide introductory information to early career hydrologists interested in sharing their work publicly via preprint. At this time, I’ve only submitted one paper for preprint; therefore, I’m inexperienced. It’d be interesting to hear from other early career scientists about how they’ve negotiated publication of preprints with more established scientists, particularly when it addressing points listed under ‘Disadvantages’ above.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Climate Risk Assessment in Western North Carolina</title>
      <link>/project/nc-sociohydro-project/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 -0400</pubDate>
      
      <guid>/project/nc-sociohydro-project/</guid>
      <description>

&lt;h1 id=&#34;collaborators&#34;&gt;Collaborators&lt;/h1&gt;

&lt;p&gt;BB Cutts (NC State), RE Emanuel (NC State), KL Martin (NC State), KM Suttles (USFS), JM Vose (USFS), DN Wear (USFS), JW Coulston (USFS)&lt;/p&gt;

&lt;h1 id=&#34;timeline&#34;&gt;Timeline&lt;/h1&gt;

&lt;p&gt;2017-2019&lt;/p&gt;

&lt;h1 id=&#34;project-goal&#34;&gt;Project Goal&lt;/h1&gt;

&lt;p&gt;The goal of this project is to combine past and future hydrology model (i.e., &lt;a href=&#34;https://swat.tamu.edu/&#34; target=&#34;_blank&#34;&gt;Soil and Water Assessment Tool (SWAT)&lt;/a&gt;) outputs with demographics data to create maps and prioritize climate change adaptation planning for especially vulnerable communities in western North Carolina&amp;rsquo;s Yadkin-Pee Dee River Watershed.&lt;/p&gt;

&lt;h1 id=&#34;project-links&#34;&gt;Project Links&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/sheilasaia/paper-yadkin-swat-study&#34; target=&#34;_blank&#34;&gt;GitHub Repository for Suttles et al. 2018&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/sheilasaia/paper-yadkin-swat-svi-study&#34; target=&#34;_blank&#34;&gt;GitHub Repository for Saia et al. 2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h1&gt;

&lt;p&gt;Special thanks to the &lt;a href=&#34;https://orise.orau.gov/&#34; target=&#34;_blank&#34;&gt;Oak Ridge Institute for Science and Education&lt;/a&gt; for support this work.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calculating the Cost of My Flight&#39;s Carbon Footprint in R</title>
      <link>/post/2019-04-19-carbon-cost-calcs/</link>
      <pubDate>Thu, 18 Apr 2019 21:12:00 -0500</pubDate>
      
      <guid>/post/2019-04-19-carbon-cost-calcs/</guid>
      <description>


&lt;div id=&#34;background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Background&lt;/h1&gt;
&lt;p&gt;Much of my postdoctoral research is focused on studying (and building tools to help decision makers mitigate) the impacts of climate change on communities in North Carolina. I’m also committed to reducing my carbon footprint and have read &lt;a href=&#34;https://www.nytimes.com/2017/07/27/climate/airplane-pollution-global-warming.html&#34;&gt;over&lt;/a&gt; and &lt;a href=&#34;https://www.vox.com/energy-and-environment/2019/1/11/18177118/airlines-climate-change-emissions-travel&#34;&gt;over&lt;/a&gt; that flying makes up the largest fraction of an average person’s carbon dioxide emissions. In early January I decided that I wanted to try to reduce the number of flights I took in 2019. I also wanted to figure out how to offset the cost of my carbon dioxide emissions when it was going to be tough to avoid flying.&lt;/p&gt;
&lt;p&gt;I started researching websites to help me figure out how much to offset. I found several tools to calculate carbon dioxide emissions (e.g., &lt;a href=&#34;https://www.carbonfootprint.com/calculator.aspx&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://www.carbonify.com/carbon-calculator.htm&#34;&gt;here&lt;/a&gt;) but couldn’t find any that told me how much to donate based on these emissions. Early on, I decided my offsets would go to a local organization addressing climate change. For me this looked like a non-profit focused on building solar panels in the Raleigh-Durham area, but for you, it might be something different. I was doing these calculations manually and then I realized it would be more fun and more efficient to automate them in &lt;code&gt;R&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;In this post, I’m starting with flights but maybe I’ll branch out to &lt;a href=&#34;https://www.yaleclimateconnections.org/2015/09/evolving-climate-math-of-flying-vs-driving/&#34;&gt;driving&lt;/a&gt; in the future…and maybe someday a shiny app for both.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE!&lt;/strong&gt; If you’re not an R-user but you’d still like to learn how much you should donate to offset the carbon dioxide you emit from flying, &lt;em&gt;please scroll to the bottom of this post&lt;/em&gt;. I’ve included step-by-step directions for how to do this without &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;goals-of-this-post&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Goals of This Post&lt;/h1&gt;
&lt;p&gt;The main goals of this post are to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Calculate how much carbon dioxide is emitted for flights&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Calculate how much to donate based on this carbon footprint&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Write a function to automate these calculations&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks to friends for their encouragement and to the &lt;a href=&#34;https://www.fridaysforfuture.org/&#34;&gt;#fridaysforthefuture&lt;/a&gt; movement for inspiring this post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;set-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Set Up&lt;/h1&gt;
&lt;p&gt;Let’s load the library we’ll need for this post. We’ll use the &lt;a href=&#34;https://cran.r-project.org/web/packages/airportr/vignettes/Introduction_to_Airportr.html&#34;&gt;&lt;code&gt;airportr&lt;/code&gt; package&lt;/a&gt;, which has helpful functions for looking up airport codes and calculating the distances between airports.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(airportr)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;all-the-airports&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;All the Airports&lt;/h1&gt;
&lt;p&gt;There are many airports around the world and you might not know the 3-letter International Air Transport Association (IATA) code for the airports. Luckily, the &lt;a href=&#34;https://cran.r-project.org/web/packages/airportr/vignettes/Introduction_to_Airportr.html&#34;&gt;&lt;code&gt;airportr&lt;/code&gt; package&lt;/a&gt; has a look-up table function to help with this.&lt;/p&gt;
&lt;p&gt;In this example, let’s calculate the amount we can donate to offset the carbon dioxide emissions for a flight from Raleigh/Durham, NC (departure city) to Charlotte, NC (arrival city).&lt;/p&gt;
&lt;p&gt;Let’s start by looking up airports with “Raleigh” in their name.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;airport_lookup(input = &amp;quot;Raleigh&amp;quot;, input_type = &amp;quot;name&amp;quot;, output_type = &amp;quot;IATA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in airport_lookup(input = &amp;quot;Raleigh&amp;quot;, input_type = &amp;quot;name&amp;quot;, output_type =
## &amp;quot;IATA&amp;quot;): No exact matches but some similar names in the database include:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## General Ignacio P. Garcia International Airport
## Licenciado y General Ignacio Lopez Rayon Airport
## Rabigh Airport
## Raleigh Durham International Airport
## Raleigh County Memorial Airport
## Leigh Creek Airport&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There were several results but the Raleigh Durham International Airport is the one we want. Let’s use that as the new look-up function input.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;airport_lookup(input = &amp;quot;Raleigh Durham International Airport&amp;quot;, input_type = &amp;quot;name&amp;quot;, output_type = &amp;quot;IATA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;RDU&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This time we get get the 3-digit IATA code for our departure city: RDU.&lt;/p&gt;
&lt;p&gt;If you think you know the 3-digit IATA code for your airport of interests, you can also use the look-up functions to double check. Let’s do this for the arrival city, which I’m pretty sure is CLT.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;airport_lookup(input = &amp;quot;CLT&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Charlotte Douglas International Airport&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great! Looks like CLT was a good guess for for the Charlotte, NC airport.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculate-the-distance-between-airports&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Calculate the Distance Between Airports&lt;/h1&gt;
&lt;p&gt;Now that we know the departure and arrival city IATA codes, we can use them to calculate the distance between RDU and CLT. The &lt;code&gt;airportr&lt;/code&gt; package also has a function for this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kilometers &amp;lt;- round(airport_distance(&amp;quot;RDU&amp;quot;, &amp;quot;CLT&amp;quot;))
miles &amp;lt;- round(airport_distance(&amp;quot;RDU&amp;quot;, &amp;quot;CLT&amp;quot;) * 0.621)

kilometers&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 209&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;miles&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 130&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 209 km (or 130 mi) between the RDU and CLT airports (as a crow flies).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;carbon-dioxide-emission-calculations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Carbon Dioxide Emission Calculations&lt;/h1&gt;
&lt;p&gt;To calculate our carbon dioxide emissions we’ll need to know how much carbon dioxide is emitted per mile traveled per person. Thankfully, many people before me have worked out this calculation. One of the most thorough descriptions of this is available at &lt;a href=&#34;https://blueskymodel.org/air-mile&#34;&gt;blueskymodel.org&lt;/a&gt;. After stepping through their calculations, this website recommends that 1 air mile produces 0.24 pounds of carbon dioxide emitted per person.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Radiative_forcing&#34;&gt;Radiative forcing&lt;/a&gt; is important to consider with respect to flight emissions calculations because it allows us to account for the fact that our plane is closer to the top of the atmosphere when it is admitting carbon dioxide. This matters because carbon dioxide emitted higher up in the Earth’s atmosphere has a greater warming potential then carbon dioxide emitted by our cars, etc. on the Earth’s surface. To account for radiative forcing, we can multiply our emission calculation by a factor. The website &lt;a href=&#34;https://carbonfund.org/how-we-calculate/&#34;&gt;carbonfund.org&lt;/a&gt; recommends this factor be equal to 1.891.&lt;/p&gt;
&lt;p&gt;The full calculation for metric tons of carbon oxide emitted with radiative forcing is given below. The (1/2204.62) helps us convert from pounds to metric tons.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;num_people &amp;lt;- 1
co2_emitted &amp;lt;- miles * num_people * 0.24 * (1 / 2204.62) * 1.891

round(co2_emitted, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.027&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When one person travels one-way from RDU to CLT, they emit 0.027 metric tons (or 59 pounds) of carbon dioxide.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;carbon-dioxcide-offset-calculations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Carbon Dioxcide Offset Calculations&lt;/h1&gt;
&lt;p&gt;Next, we’ll need to figure out how much to donate given these carbon dioxide emissions. To do this, we can refer to the US Environmental Protection Agency’s (USEPA) &lt;a href=&#34;https://19january2017snapshot.epa.gov/sites/production/files/2016-12/documents/sc_co2_tsd_august_2016.pdf&#34;&gt;Social Cost of Carbon Technical Report&lt;/a&gt;. The information we’ll need is found in Table 2 of this document. We can save this information to a dataframe. The social cost of carbon includes the impact of carbon dioxide emissions on: “…changes in net agricultural productivity, human health, property damages from increased flood risk, and changes in energy system costs, such as reduced costs for heating and increased costs for air conditioning.” (&lt;a href=&#34;https://19january2017snapshot.epa.gov/climatechange/social-cost-carbon_.html&#34;&gt;USEPA, 2017&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;social_cost_co2 &amp;lt;- data.frame(
  year = seq(2015, 2050, 5),
  avg_5_perc_usd_per_ton_co2 = c(11, 12, 14, 16, 18, 21, 23, 26),
  avg_3_perc_usd_per_ton_co2 = c(36, 42, 46, 50, 55, 60, 64, 69),
  avg_2.5_perc_usd_per_ton_co2 = c(56, 62, 68, 73, 78, 84, 89, 95),
  high_impact_usd_per_ton_co2 = c(105, 123, 138, 152, 168, 183, 197, 212)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s walk through each of these columns. Column 1 is the year, which ranges from 2015 to 2050. Columns 2 to 5 all represent the cost (in US dollars) of emitting a metric ton of carbon dioxide given different future strategies. That is, the average (of three climate models times five climate change scenarios) cost given a 5%, 3%, and 2.5% discount rate for columns 2 through 4, respectively. I’ll admit that I don’t fully understand the discount rate, but believe it’s used as a way to consider whether people are more likely to value short-term or long-term risks associated with climate change. The larger the discount rate, the less they value long-term risk. In a societal context, the larger discount rate suggests that current generations are valued more than future generations. The report also includes a high impact case that is calculated from the 95th percentile (of three climate models times five climate change scenarios), rather than the average, cost given a 3% discount rate. The USEPA’s &lt;a href=&#34;https://19january2017snapshot.epa.gov/sites/production/files/2016-12/documents/sc_co2_tsd_august_2016.pdf&#34;&gt;Social Cost of Carbon Technical Report&lt;/a&gt; report says, “…there is extensive evidence in the scientific and economic literature of the potential for lower-probability, higher-impact outcomes from climate change, which would be particularly harmful to society and thus relevant to the public and policymakers.” Therefore, for this blog post, we’ll move forward using the high impact case.&lt;/p&gt;
&lt;p&gt;We can fit this linear trend and use it to estimate the cost of a metric ton of carbon dioxide emitted for years not in Table 2 (i.e., for this year, 2019).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fit a linear model
cost_lm &amp;lt;- lm(high_impact_usd_per_ton_co2 ~ year, data = social_cost_co2)

# save the model parameters for prediction
intercept &amp;lt;- cost_lm$coefficients[1]
slope &amp;lt;- cost_lm$coefficients[2]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s plot the data (points) and linear model (line).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(high_impact_usd_per_ton_co2 ~ year, data = social_cost_co2, pch = 16, xlab = &amp;quot;Year&amp;quot;, ylab = &amp;quot;Cost per Metric Ton CO2 Emitted (USD)&amp;quot;)
abline(a = intercept, b = slope, col = &amp;quot;red&amp;quot;, lwd = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-19-carbon-cost-calcs_files/figure-html/plot%20cost%20model-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ok, now we can use the model parameters to predict the cost for a given year. Let’s try this for 2019.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_year &amp;lt;- 2019
my_year * slope + intercept&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     year 
## 118.9286&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The social cost of a metric ton of carbon dioxide emitted in 2019 is $119.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-it-all-together-aka-making-an-r-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Putting it All Together (aka Making an R Function)&lt;/h1&gt;
&lt;p&gt;Now let’s take all the code we wrote above and combine it into a custom R function that calculates how much we can donate to offset the carbon dioxide emissions for a new flight. In this second example, we’ll fly round-trip from Raleigh/Durham, NC (departure city) to San Francisco, CA (arrival city).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;carbon_offset_cost &amp;lt;- function(departing_airport_code, arriving_airport_code, year, num_people, radiative_force = TRUE, round_trip = FALSE) {
  # year should range from 2015 - 2050 to assume linearity
  # departing_airport_code and arriving_airport code are three letter airport codes
  # radiative_force = TRUE (default) will use radiative forcing in the calculation
  # set to FALSE to avoid using radiative forcing
  # round_trip = FALSE (default) will double the cost calculation if set to TRUE
  # carbon offset result is given in USD
  
  # note: you will need to load the airportr package before using this function
  
  # linear coefficients from high impact column of table 2
  # source: https://19january2017snapshot.epa.gov/sites/production/files/2016-12/documents/sc_co2_tsd_august_2016.pdf
  intercept &amp;lt;- (-5986.143)
  slope &amp;lt;- 3.02381
  
  # calculate miles flown
  miles &amp;lt;- round(airport_distance(departing_airport_code, arriving_airport_code) * 0.621)
  
  if (radiative_force == TRUE) {
    # metric tons of co2 emitted w/ radiative forcing
    co2_emitted &amp;lt;- miles * num_people * 0.24 * (1 / 2204.62) * 1.891
    # source: https://blueskymodel.org/air-mile (for emission conversion factor per person)
    # source: https://carbonfund.org/how-we-calculate/ (for carbon forcing coefficient)
    
    # cost in usd
    if (round_trip == FALSE) {
      # one-way
      cost &amp;lt;- co2_emitted * (slope * year + intercept)
    }
    
    else if (round_trip == TRUE) {
      # round-trip
      cost &amp;lt;- co2_emitted * (slope * year + intercept) * 2
    }
  }
  
  else if (radiative_force == FALSE) {
    # metric tons of co2 emitted w/out radiative forcing
    co2_emitted &amp;lt;- miles * num_people * 0.24 * (1 / 2204.62) 
    
    # cost in usd
    if (round_trip == FALSE) {
      # one-way
      cost &amp;lt;- co2_emitted * (slope * year + intercept)
    }
    
    else if (round_trip == TRUE) {
      # round-trip
      cost &amp;lt;- co2_emitted * (slope * year + intercept) * 2
    }  
  }
  
  else {
    cost &amp;lt;- NA
  }
  
  return(cost)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s test out the function for a round-trip flight from RDU to SFO (for 1 person).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;carbon_offset_cost(departing_airport_code = &amp;quot;RDU&amp;quot;, 
                   arriving_airport_code = &amp;quot;SFO&amp;quot;,
                   year = 2019,
                   num_people = 1,
                   radiative_force = TRUE,
                   round_trip = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 117.2229&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looks like we can donate $117 to ofset the carbon dioxide emitted from our round-trip flight from RDU to SFO in 2019. If we want to be more generous we can adjust the year for a future period. For example, if we change the year to the maximum value, 2050, we can donate $210. Our emissions are more expensive the further out in time we go (see the &lt;a href=&#34;https://19january2017snapshot.epa.gov/climatechange/social-cost-carbon_.html&#34;&gt;USEPA Social Cost of Carbon website&lt;/a&gt; for more information).&lt;/p&gt;
&lt;p&gt;Some other thoughts that I wanted to mention before signing off:&lt;/p&gt;
&lt;p&gt;Unless you’re an R user, I recognize that it will take extra work for you to figure out how much you should donate to offset your flight’s carbon dioxide emissions. The first task is for me to start writing a second post for non-R users, and in the mean time, I’ll give an example below to put this all into perspective for &lt;em&gt;non-R users&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-if-im-not-an-r-user&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What if I’m not an R user?&lt;/h1&gt;
&lt;p&gt;Here are some of the basic calculations you’d need to make if you are not an R user and want to calculate your carbon foot print for a flight you’re taking.&lt;/p&gt;
&lt;p&gt;Steps:&lt;br/&gt;
1. Determine the mileage between your arrival and destination airports in miles (i.e., jot this down as variable &lt;code&gt;miles&lt;/code&gt;). Use a website like &lt;a href=&#34;https://www.airmilescalculator.com/&#34;&gt;this&lt;/a&gt;.&lt;br/&gt;
2. Decide how many people (i.e., jot this down as variable &lt;code&gt;num_people&lt;/code&gt;) are traveling and whether the trip is a round-trip or one way.&lt;br/&gt;
3. If a one-way trip, use the formula: &lt;code&gt;co2_emitted = miles x num_people x 0.24 x (1 / 2204.62) x 1.891&lt;/code&gt; to determine the metric tons of carbon dioxide emitted from your flight. Don’t forget the &lt;a href=&#34;https://www.mathsisfun.com/operation-order-pemdas.html&#34;&gt;order of operations&lt;/a&gt; here. ;) The variable &lt;code&gt;miles&lt;/code&gt; comes from step 1 and the variable &lt;code&gt;num_people&lt;/code&gt; comes from step 2. If round-trip, calculate &lt;code&gt;co2_emitted&lt;/code&gt; as mentioned previously and multiply this by 2 since you’re traveling to your destination and back.&lt;br/&gt;
4. Think about whether you view climate change as a short- or long-term goal. If you think of it based on short-term impacts only then choose the current year (i.e., jot this down as variable &lt;code&gt;year&lt;/code&gt; = 2019). However, if you are commited to addressing its more long-term impacts, you can choose any year up until 2050 (i.e. jot this down as variable &lt;code&gt;year&lt;/code&gt; = 2050). The closer to 2050 you choose, the larger your donation will be.&lt;br/&gt;
5. Calculate the cost of your offset (i.e., how much you’ll donate) using the formula: &lt;code&gt;cost = co2_emitted x (3.02 x year - 5986.1)&lt;/code&gt;. Remember your &lt;a href=&#34;https://www.mathsisfun.com/operation-order-pemdas.html&#34;&gt;order of operations&lt;/a&gt;. The variable &lt;code&gt;co2_emitted&lt;/code&gt; comes from step 3 and the variable &lt;code&gt;year&lt;/code&gt; comes from step 4.&lt;br/&gt;
6. Donate this amount (in US dollars) to your local climate change organization (e.g., one building solar panels, planting trees, or advocating for bicycle lanes).&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;If have questions, comments, or ideas related to this post, please let me know!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
